<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>OneR by Holger von Jouanne-Diedrich (vonjd)</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">OneR</h1>
      <h2 class="project-tagline">Establishing a New Baseline for Machine Learning Classification Models</h2>
      <a href="https://github.com/vonjd/OneR" class="btn">View on GitHub</a>
      <a href="https://github.com/vonjd/OneR/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/vonjd/OneR/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      
<h2>Introduction</h2>
<p>The following story is one of the most often told in the Data Science community: Some time ago the military built a system which aim it was to distinguish military vehicles from civilian ones. They chose a neural network approach and trained the system with pictures of tanks, humvees and misile launchers on the one hand and normal cars, pickups and trucks on the other. And after having reached a satisfactory accuracy they brought the system into the field (quite literary). It failed completely, performing no better than a coin toss. What had happened? No one knew, so they re-engineered the black box (no small feat in itself) and found that most of the military pics where taken at dusk or dawn and most civilian pics under brighter weather conditions. The neural net had learned the difference between light and dark!
  Although this might be an urban legend the fact that it is so often told wants to tell us something:
<ol>
  <li>Many of our Machine Learning models are so complex that we cannot understand them ourselves.</li>
  <li>Because of 1. we cannot differentiate between the simpler aspects of a problem which can be tackled by simple models and the more sophisticated ones which need specilized treatment.</li>
</ol>
The above is not only true for neural networks (and especially deep neural networks) but for most of the methods used today, especially Support Vector Machines and Random Forrests and in general all kinds of ensemble based methods.
In one word: We need a good baseline which builds “the best simple model” that strikes a balance between the best accuracy possible with a model that is still simple to grasp: We have developed the OneR package for finding this sweet spot and thereby establishing a new baseline for classification models in Machine Learning.

This package is filling a longstanding gap because only a JAVA based implementation was available so far (<a href="https://cran.r-project.org/web/packages/RWeka/index.html">RWeka package</a>&nbsp;as an interface for the <a href="http://weka.sourceforge.net/doc.dev/weka/classifiers/rules/OneR.html">OneR JAVA class</a>). Additionally several enhancements have been made (see below).
</p>

<h2>Design princples for the OneR package</h2>
<p>The following design principles were followed for programming the package:</p>
<ul>
  <li>Easy: The learning curve for new users should be minimal. Results should be obtained with ease and only minimal preprocessing and modeling steps should be necessary.</li>
  <li>Versatile: All types of data, i.e. categorical and numeric, should be computable - as input variable as well as as target.</li>
  <li>Fast: The running times of model trainings should be short.</li>
  <li>Accurate: The accuracy of trained models should be good overall.</li>
  <li>Robust: Models should not be prone to overfitting; the rached accuracy on training data should be comparable to the accuracy of predictions from new, unseen cases.</li>
  <li>Comprehensible: It should be easy to understand which rules the model has learned. Not only should the rules be easily comprehensible but they should serve as heuristics that are usable even without a computer.</li>
  <li>Reproducible: Because the used algorithms are strictly deterministic one will always get the same models on the same data. Many ML algorithms have stochastic components so that the data scientist will get a different model very time.</li>
  <li>Inituitive: Model diagnostics should be presented in form of a simple plot.</li>
  <li>Native R: The whole package is written in native R code. Thereby the sourcecode can be easily checked and the whole package is very lean.</li>
</ul>
<p>The package is based on the – as the name might reveal – one rule classification algorithm [Holte93]. Although the underlying method is simple enough (basically 1-level decision trees) several enhancements have been made:</p>
<ul>
  <li><span style="text-decoration: underline;">Missing values</span>: In the original algorithm missing values were always handled as a separate level in the respective attribute. While missing values can sometimes reveal interesting patterns in other cases they are, well, just values that are missing. In the OneR package missing values can be handled as separate levels (level &ldquo;NA&rdquo;) or they can be omitted.</li>
  <li><span style="text-decoration: underline;">Discretization of numeric data</span>: The OneR algorithm can only handle categoric data so numeric data has to be discretized. The original OneR algorithm separates the respective values in ever smaller and smaller buckets until the best possible accuracy is being reached. In can be argued (as has been [Weka&hellip;] that this is <em>the</em> definition of overfitting and contradicts the original spirit of OneR because tons of rules (one for every bucket) will result. One can of course introduce a new parameter &ldquo;maximum bucket size&rdquo; but finding the right value for this one doesn&rsquo;t come naturally either. Therefore, we take a radically different approach: There are several methods for handling numeric data in the package (in the bin and the optbin function), the most promising one is the &ldquo;logreg&rdquo; method in the optbin function which gives only as many bins as there are target categories and which optimizes the cut points according to pairwise logistic regressions. The performance of this method on several different datasets is very encouraging and the method will be explained in detail later.</li>
  <li><span style="text-decoration: underline;">Tie breaking</span>: Sometimes the OneR algorihm will find several attributes that provide rules which all give the same best accuracy. The original algorithm just took the first attribute. While this is implemented in the OneR function as the default too a different method for tie breaking can be chosen: The contingency tables of all &ldquo;best&rdquo; rules are tested against each other with a Pearson&rsquo;s Chi squared test and the one with the smallest p-value is being chosen. The rationale behind this is that thereby the attribute with the best signal-to-noise ratio is being found.</li>
</ul>
<h2>A simple example</h2>
<pre><code>library(OneR)</code></pre>
<p>Determine optimal bins for numeric data</p>
<pre><code>data <- optbin(iris)</code></pre>
<p>Build model with best predictor</p>
<pre><code>model <- OneR(data, verbose = TRUE)
        
    Attribute    Accuracy
1 * Petal.Width  96%     
2   Petal.Length 95.33%  
3   Sepal.Length 74.67%  
4   Sepal.Width  55.33%  
---
Chosen attribute due to accuracy
and ties method (if applicable): '*'
</code></pre>
<p>Show learned rules and model diagnostics</p>
<pre><code>summary(model)

Rules:
If Petal.Width = (0.0976,0.791] then Species = setosa
If Petal.Width = (0.791,1.63]   then Species = versicolor
If Petal.Width = (1.63,2.5]     then Species = virginica

Accuracy:
144 of 150 instances classified correctly (96%)

Contingency table:
            Petal.Width
Species      (0.0976,0.791] (0.791,1.63] (1.63,2.5] Sum
  setosa               * 50            0          0  50
  versicolor              0         * 48          2  50
  virginica               0            4       * 46  50
  Sum                    50           52         48 150
---
Maximum in each column: '*'

Pearson's Chi-squared test:
X-squared = 266.35, df = 4, p-value < 2.2e-16
</code></pre>
<p>Plot model diagnostics</p>
<pre><code>plot(model)</code></pre>
<p>Use model to predict data</p>
<pre><code>prediction <- predict(model, data)</code></pre>
<p>Evaluate prediction statistics</p>
<pre><code>eval_model(prediction, data)

           actual            
prediction   setosa versicolor virginica Sum
  setosa         50          0         0  50
  versicolor      0         48         4  52
  virginica       0          2        46  48
  Sum            50         50        50 150

           actual            
prediction   setosa versicolor virginica  Sum
  setosa       0.33       0.00      0.00 0.33
  versicolor   0.00       0.32      0.03 0.35
  virginica    0.00       0.01      0.31 0.32
  Sum          0.33       0.33      0.33 1.00

Accuracy:
0.96 (144/150)

Error rate:
0.04 (6/150)
</code></pre>

<h3>Sources</h3>
<p>[Holte93]: R. Holte: Very Simple Classification Rules Perform Well on Most Commonly Used Datasets, 1993. Available: http://www.mlpack.org/papers/ds.pdf.</p>
<h3>
<a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Support or Contact</h3>

<p>I would love to hear about your experiences with the OneR package. Please drop me a note - you can reach me on my university account: 
<a href="https://www.h-ab.de/nc/eng/about-aschaffenburg-university-of-applied-sciences/organisation/personal/?tx_fhapersonal_pi1%5BshowUid%5D=jouanne-diedrich">Holger K. von Jouanne-Diedrich</a></p>

<h3>
<a id="help-overview" class="anchor" href="#help-overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Help overview</h3>

<div class="highlight highlight-r"><pre>help(<span class="pl-v">package</span> <span class="pl-k">=</span> <span class="pl-smi">OneR</span>)</pre></div>

<p>or view the documentation on <a href="http://cran.r-project.org/web/packages/rlist/rlist.pdf">CRAN</a></p>

<h3>
<a id="license" class="anchor" href="#license" aria-hidden="true"><span class="octicon octicon-link"></span></a>License</h3>

<p>This package is under <a href="https://raw.githubusercontent.com/vonjd/OneR/master/LICENSE">MIT License</a>.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/vonjd/OneR">OneR</a> is maintained by <a href="https://github.com/vonjd">vonjd</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
