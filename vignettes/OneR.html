<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="An R package by Holger K. von Jouanne-Diedrich" />

<meta name="date" content="2016-08-05" />

<title>OneR - Establishing a New Baseline for Machine Learning Classification Models</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">OneR - Establishing a New Baseline for Machine Learning Classification Models</h1>
<h4 class="author"><em>An R package by Holger K. von Jouanne-Diedrich</em></h4>
<h4 class="date"><em>2016-08-05</em></h4>



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>The following story is one of the most often told in the Data Science community: Some time ago the military built a system which aim it was to distinguish military vehicles from civilian ones. They chose a neural network approach and trained the system with pictures of tanks, humvees and missile launchers on the one hand and normal cars, pickups and trucks on the other. After having reached a satisfactory accuracy they brought the system into the field (quite literally). It failed completely, performing no better than a coin toss. What had happened? No one knew, so they re-engineered the black box (no small feat in itself) and found that most of the military pics where taken at dusk or dawn and most civilian pics under brighter weather conditions. The neural net had learned the difference between light and dark!</p>
<p>Although this might be an urban legend the fact that it is so often told wants to tell us something:</p>
<ol style="list-style-type: decimal">
<li>Many of our Machine Learning models are so complex that we cannot understand them ourselves.</li>
<li>Because of 1. we cannot differentiate between the simpler aspects of a problem which can be tackled by simple models and the more sophisticated ones which need specialized treatment.</li>
</ol>
<p>The above is not only true for neural networks (and especially deep neural networks) but for most of the methods used today, especially Support Vector Machines and Random Forests and in general all kinds of ensemble based methods.</p>
<p>In one word: We need a good baseline which builds “the best simple model” that strikes a balance between the best accuracy possible with a model that is still simple enough to understand: I have developed the OneR package for finding this sweet spot and thereby establishing a new baseline for classification models in Machine Learning (ML).</p>
<p>This package is filling a longstanding gap because only a JAVA based implementation was available so far (<a href="https://cran.r-project.org/web/packages/RWeka/index.html">RWeka package</a> as an interface for the <a href="http://weka.sourceforge.net/doc.dev/weka/classifiers/rules/OneR.html">OneR JAVA class</a>). Additionally several enhancements have been made (see below).</p>
</div>
<div id="design-principles-for-the-oner-package" class="section level2">
<h2>Design principles for the OneR package</h2>
<p>The following design principles were followed for programming the package:</p>
<ul>
<li>Easy: The learning curve for new users should be minimal. Results should be obtained with ease and only minimal preprocessing and modeling steps should be necessary.</li>
<li>Versatile: All types of data, i.e. categorical and numeric, should be computable - as input variable as well as as target.</li>
<li>Fast: The running times of model trainings should be short.</li>
<li>Accurate: The accuracy of trained models should be good overall.</li>
<li>Robust: Models should not be prone to overfitting; the reached accuracy on training data should be comparable to the accuracy of predictions from new, unseen cases.</li>
<li>Comprehensible: It should be easy to understand which rules the model has learned. Not only should the rules be easily comprehensible but they should serve as heuristics that are usable even without a computer.</li>
<li>Reproducible: Because the used algorithms are strictly deterministic one will always get the same models on the same data. Many ML algorithms have stochastic components so that the data scientist will get a different model every time.</li>
<li>Intuitive: Model diagnostics should be presented in form of simple tables and plots.</li>
<li>Native R: The whole package is written in native R code. Thereby the source code can be easily checked and the whole package is very lean. Additionally the package has no dependencies at all other than base R itself.</li>
</ul>
<p>The package is based on the – as the name might reveal – one rule classification algorithm [Holte93]. Although the underlying method is simple enough (basically 1-level decision trees, you can find out more here: <a href="http://www.saedsayad.com/oner.htm">OneR</a>) several enhancements have been made:</p>
<ul>
<li>Discretization of numeric data: The OneR algorithm can only handle categorical data, so numeric data has to be discretized. The original OneR algorithm separates the respective values in ever smaller and smaller buckets until the best possible accuracy is being reached. It can be argued that this is the definition of overfitting and contradicts the original spirit of OneR because tons of rules (one for every bucket) will result. One can of course introduce a new parameter “maximum bucket size” but finding the right value for this one doesn’t come naturally either. Therefore I take a radically different approach: There are several methods for handling numeric data in the package (in the bin and the optbin function), the most promising one is the (default) “logreg” method in the optbin function which gives only as many bins as there are target categories and which optimizes the cut points according to pairwise logistic regressions.</li>
<li>Missing values: In the original algorithm missing values were always handled as a separate level in the respective attribute. While missing values can sometimes reveal interesting patterns in other cases they are, well, just values that are missing. In the OneR package missing values can be handled as separate levels (level “NA”) or they can be omitted (the default).</li>
<li>Tie breaking: Sometimes the OneR algorithm will find several attributes that provide rules which all give the same best accuracy. The original algorithm just took the first attribute. While this is implemented in the OneR function as the default too a different method for tie breaking can be chosen: The contingency tables of all “best” rules are tested against each other with a Pearson’s Chi squared test and the one with the smallest p-value is being chosen. The rationale behind this is that thereby the attribute with the best signal-to-noise ratio is being found.</li>
</ul>
</div>
<div id="getting-started-with-a-simple-example" class="section level2">
<h2>Getting started with a simple example</h2>
<p>You can also watch this video which goes through the following example step-by-step:</p>
<p><a href="https://www.youtube.com/watch?v=AGC0oRlXxgU">Quick Start Guide for the OneR package (Video)</a></p>
<p>After installing from CRAN load package</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(OneR)</code></pre></div>
<p>Use the famous Iris dataset and determine optimal bins for numeric data</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw">optbin</span>(iris)</code></pre></div>
<p>Build model with best predictor</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">OneR</span>(data, <span class="dt">verbose =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## 
##     Attribute    Accuracy
## 1 * Petal.Width  96%     
## 2   Petal.Length 95.33%  
## 3   Sepal.Length 74.67%  
## 4   Sepal.Width  55.33%  
## ---
## Chosen attribute due to accuracy
## and ties method (if applicable): '*'</code></pre>
<p>Show learned rules and model diagnostics</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## OneR(data = data, verbose = TRUE)
## 
## Rules:
## If Petal.Width = (0.0976,0.791] then Species = setosa
## If Petal.Width = (0.791,1.63]   then Species = versicolor
## If Petal.Width = (1.63,2.5]     then Species = virginica
## 
## Accuracy:
## 144 of 150 instances classified correctly (96%)
## 
## Contingency table:
##             Petal.Width
## Species      (0.0976,0.791] (0.791,1.63] (1.63,2.5] Sum
##   setosa               * 50            0          0  50
##   versicolor              0         * 48          2  50
##   virginica               0            4       * 46  50
##   Sum                    50           52         48 150
## ---
## Maximum in each column: '*'
## 
## Pearson's Chi-squared test:
## X-squared = 266.35, df = 4, p-value &lt; 2.2e-16</code></pre>
<p>Plot model diagnostics</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(model)</code></pre></div>
<p><img src="data:image/png;base64,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" alt /><!-- --></p>
<p>Use model to predict data</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(model, data)</code></pre></div>
<p>Evaluate prediction statistics</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">eval_model</span>(prediction, data)</code></pre></div>
<pre><code>## 
## Confusion matrix (absolute):
##             actual
## prediction   setosa versicolor virginica Sum
##   setosa         50          0         0  50
##   versicolor      0         48         4  52
##   virginica       0          2        46  48
##   Sum            50         50        50 150
## 
## Confusion matrix (relative):
##             actual
## prediction   setosa versicolor virginica  Sum
##   setosa       0.33       0.00      0.00 0.33
##   versicolor   0.00       0.32      0.03 0.35
##   virginica    0.00       0.01      0.31 0.32
##   Sum          0.33       0.33      0.33 1.00
## 
## Accuracy:
## 0.96 (144/150)
## 
## Error rate:
## 0.04 (6/150)</code></pre>
<p>Please note that the very good accuracy of 96% is reached effortlessly.</p>
<p>“Petal.Width” is identified as the attribute with the highest predictive value. The cut points of the intervals are found automatically (via the included optbin function). The results are three very simple, yet accurate, rules to predict the respective species.</p>
<p>The nearly perfect separation of the colors in the diagnostic plot give a good indication of the model’s ability to separate the different species.</p>
</div>
<div id="a-more-sophisticated-real-world-example" class="section level2">
<h2>A more sophisticated real-world example</h2>
<p>The next example tries to find a model for the identification of breast cancer. The data were obtained from the UCI machine learning repository (see also the package documentation). According to this source the best out-of-sample performance was 95.9%, so let’s see what we can achieve with the OneR package…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(breastcancer)
data &lt;-<span class="st"> </span>breastcancer</code></pre></div>
<p>Divide training (80%) and test set (20%)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12</span>) <span class="co"># for reproducibility</span>
random &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(data), <span class="fl">0.8</span> *<span class="st"> </span><span class="kw">nrow</span>(data))
data_train &lt;-<span class="st"> </span><span class="kw">optbin</span>(data[random, ])</code></pre></div>
<pre><code>## Warning in optbin(data[random, ]): 12 instance(s) removed due to missing
## values</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_test &lt;-<span class="st"> </span>data[-random, ]</code></pre></div>
<p>Train OneR model on training set</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_train &lt;-<span class="st"> </span><span class="kw">OneR</span>(data_train, <span class="dt">verbose =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## 
##     Attribute                   Accuracy
## 1 * Uniformity of Cell Size     92.69%  
## 2   Uniformity of Cell Shape    91.77%  
## 3   Bland Chromatin             90.31%  
## 4   Bare Nuclei                 89.58%  
## 5   Single Epithelial Cell Size 88.12%  
## 6   Normal Nucleoli             86.29%  
## 7   Marginal Adhesion           85.74%  
## 8   Clump Thickness             84.46%  
## 9   Mitoses                     78.24%  
## ---
## Chosen attribute due to accuracy
## and ties method (if applicable): '*'</code></pre>
<p>Show model and diagnostics</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model_train)</code></pre></div>
<pre><code>## 
## Call:
## OneR(data = data_train, verbose = TRUE)
## 
## Rules:
## If Uniformity of Cell Size = (0.991,3.15] then Class = benign
## If Uniformity of Cell Size = (3.15,10]    then Class = malignant
## 
## Accuracy:
## 507 of 547 instances classified correctly (92.69%)
## 
## Contingency table:
##            Uniformity of Cell Size
## Class       (0.991,3.15] (3.15,10] Sum
##   benign           * 340         8 348
##   malignant           32     * 167 199
##   Sum                372       175 547
## ---
## Maximum in each column: '*'
## 
## Pearson's Chi-squared test:
## X-squared = 383.91, df = 1, p-value &lt; 2.2e-16</code></pre>
<p>Plot model diagnostics</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(model_train)</code></pre></div>
<p><img src="data:image/png;base64,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" alt /><!-- --></p>
<p>Use trained model to predict test set</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(model_train, data_test)</code></pre></div>
<p>Evaluate model performance on test set</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">eval_model</span>(prediction, data_test)</code></pre></div>
<pre><code>## 
## Confusion matrix (absolute):
##            actual
## prediction  benign malignant Sum
##   benign        97         5 102
##   malignant      3        35  38
##   Sum          100        40 140
## 
## Confusion matrix (relative):
##            actual
## prediction  benign malignant  Sum
##   benign      0.69      0.04 0.73
##   malignant   0.02      0.25 0.27
##   Sum         0.71      0.29 1.00
## 
## Accuracy:
## 0.9429 (132/140)
## 
## Error rate:
## 0.0571 (8/140)</code></pre>
<p>The best reported out-of-sample accuracy on this dataset was at 95.9% and it was reached with considerable effort. The reached accuracy for the test set here lies at 94.3%! This is achieved with just two simple rules!</p>
<p>“Uniformity of Cell Size” is identified as the attribute with the highest predictive value. The cut points of the intervals are again found automatically (via the included optbin function). The very good separation of the colors in the diagnostic plot give a good indication of the model’s ability to differentiate between benign and malignant tissue.</p>
</div>
<div id="included-functions" class="section level2">
<h2>Included functions</h2>
<div id="oner" class="section level3">
<h3>OneR</h3>
<p>OneR is the main function of the package. It builds a model according to the One Rule machine learning algorithm for categorical data. All numerical data is automatically converted into five categorical bins of equal length. When verbose is TRUE it gives the predictive accuracy of the attributes in decreasing order.</p>
</div>
<div id="bin" class="section level3">
<h3>bin</h3>
<p>bin discretizes all numerical data in a dataframe into categorical bins of equal length or equal content or based on automatically determined clusters.</p>
<p>Examples</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span>iris
<span class="kw">str</span>(data)</code></pre></div>
<pre><code>## 'data.frame':    150 obs. of  5 variables:
##  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
##  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
##  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
##  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
##  $ Species     : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(<span class="kw">bin</span>(data))</code></pre></div>
<pre><code>## 'data.frame':    150 obs. of  5 variables:
##  $ Sepal.Length: Factor w/ 5 levels &quot;(4.3,5.02]&quot;,&quot;(5.02,5.74]&quot;,..: 2 1 1 1 1 2 1 1 1 1 ...
##  $ Sepal.Width : Factor w/ 5 levels &quot;(2,2.48]&quot;,&quot;(2.48,2.96]&quot;,..: 4 3 3 3 4 4 3 3 2 3 ...
##  $ Petal.Length: Factor w/ 5 levels &quot;(0.994,2.18]&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Petal.Width : Factor w/ 5 levels &quot;(0.0976,0.58]&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Species     : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(<span class="kw">bin</span>(data, <span class="dt">nbins =</span> <span class="dv">3</span>))</code></pre></div>
<pre><code>## 'data.frame':    150 obs. of  5 variables:
##  $ Sepal.Length: Factor w/ 3 levels &quot;(4.3,5.5]&quot;,&quot;(5.5,6.7]&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Sepal.Width : Factor w/ 3 levels &quot;(2,2.8]&quot;,&quot;(2.8,3.6]&quot;,..: 2 2 2 2 2 3 2 2 2 2 ...
##  $ Petal.Length: Factor w/ 3 levels &quot;(0.994,2.97]&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Petal.Width : Factor w/ 3 levels &quot;(0.0976,0.9]&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Species     : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(<span class="kw">bin</span>(data, <span class="dt">nbins =</span> <span class="dv">3</span>, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;small&quot;</span>, <span class="st">&quot;medium&quot;</span>, <span class="st">&quot;large&quot;</span>)))</code></pre></div>
<pre><code>## 'data.frame':    150 obs. of  5 variables:
##  $ Sepal.Length: Factor w/ 3 levels &quot;small&quot;,&quot;medium&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Sepal.Width : Factor w/ 3 levels &quot;small&quot;,&quot;medium&quot;,..: 2 2 2 2 2 3 2 2 2 2 ...
##  $ Petal.Length: Factor w/ 3 levels &quot;small&quot;,&quot;medium&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Petal.Width : Factor w/ 3 levels &quot;small&quot;,&quot;medium&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Species     : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<p>Difference between methods “length” and “content”</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>); <span class="kw">table</span>(<span class="kw">bin</span>(<span class="kw">rnorm</span>(<span class="dv">900</span>), <span class="dt">nbins =</span> <span class="dv">3</span>))</code></pre></div>
<pre><code>## 
## (-3.01,-0.735]  (-0.735,1.54]    (1.54,3.82] 
##            212            623             65</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>); <span class="kw">table</span>(<span class="kw">bin</span>(<span class="kw">rnorm</span>(<span class="dv">900</span>), <span class="dt">nbins =</span> <span class="dv">3</span>, <span class="dt">method =</span> <span class="st">&quot;content&quot;</span>))</code></pre></div>
<pre><code>## 
## (-3.01,-0.423] (-0.423,0.444]   (0.444,3.82] 
##            300            300            300</code></pre>
<p>Method “clusters”</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">intervals &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="kw">levels</span>(<span class="kw">bin</span>(faithful$waiting, <span class="dt">nbins =</span> <span class="dv">2</span>, <span class="dt">method =</span> <span class="st">&quot;cluster&quot;</span>)), <span class="dt">collapse =</span> <span class="st">&quot; &quot;</span>)
<span class="kw">hist</span>(faithful$waiting, <span class="dt">main =</span> <span class="kw">paste</span>(<span class="st">&quot;Intervals:&quot;</span>, intervals))
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">c</span>(<span class="fl">42.9</span>, <span class="fl">67.5</span>, <span class="fl">96.1</span>), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</code></pre></div>
<p><img src="data:image/png;base64,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" alt /><!-- --></p>
<p>Handling of missing values</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bin</span>(<span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">10</span>, <span class="ot">NA</span>), <span class="dt">nbins =</span> <span class="dv">2</span>, <span class="dt">na.omit =</span> <span class="ot">FALSE</span>) <span class="co"># adds new level &quot;NA&quot;</span></code></pre></div>
<pre><code>##  [1] (0.991,5.5] (0.991,5.5] (0.991,5.5] (0.991,5.5] (0.991,5.5]
##  [6] (5.5,10]    (5.5,10]    (5.5,10]    (5.5,10]    (5.5,10]   
## [11] NA         
## Levels: (0.991,5.5] (5.5,10] NA</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bin</span>(<span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">10</span>, <span class="ot">NA</span>), <span class="dt">nbins =</span> <span class="dv">2</span>)</code></pre></div>
<pre><code>## Warning in bin(c(1:10, NA), nbins = 2): 1 instance(s) removed due to
## missing values</code></pre>
<pre><code>##  [1] (0.991,5.5] (0.991,5.5] (0.991,5.5] (0.991,5.5] (0.991,5.5]
##  [6] (5.5,10]    (5.5,10]    (5.5,10]    (5.5,10]    (5.5,10]   
## Levels: (0.991,5.5] (5.5,10]</code></pre>
</div>
<div id="optbin" class="section level3">
<h3>optbin</h3>
<p>optbin discretizes all numerical data in a dataframe into categorical bins where the cut points are optimally aligned with the target categories, thereby a factor is returned. When building a OneR model this could result in fewer rules with enhanced accuracy. The cutpoints are calculated by pairwise logistic regressions (method “logreg”) or as the means of the expected values of the respective classes (“naive”). The function is likely to give unsatisfactory results when the distributions of the respective classes are not (linearly) separable. Method “naive” should only be used when distributions are (approximately) normal, although in this case “logreg” should give comparable results, so it is the preferable (and therefore default) method.</p>
</div>
<div id="maxlevels" class="section level3">
<h3>maxlevels</h3>
<p>maxlavels removes all columns of a dataframe where a factor (or character string) has more than a maximum number of levels. Often categories that have very many levels are not useful in modelling OneR rules because they result in too many rules and tend to overfit. Examples are IDs or names.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">numeric =</span> <span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">26</span>), <span class="dt">alphabet =</span> letters)
<span class="kw">str</span>(df)</code></pre></div>
<pre><code>## 'data.frame':    26 obs. of  2 variables:
##  $ numeric : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ alphabet: Factor w/ 26 levels &quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(<span class="kw">maxlevels</span>(df))</code></pre></div>
<pre><code>## 'data.frame':    26 obs. of  1 variable:
##  $ numeric: int  1 2 3 4 5 6 7 8 9 10 ...</code></pre>
</div>
<div id="predict" class="section level3">
<h3>predict</h3>
<p>predict is a S3 method for predicting cases or probabilites based on OneR model objects. The default is a named vector with the predicted classes, if “type = prob” a matrix is returned whose columns are the probability of the first, second, etc. class.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">OneR</span>(iris)
<span class="kw">predict</span>(model, <span class="kw">data.frame</span>(<span class="dt">Petal.Width =</span> <span class="kw">seq</span>(<span class="fl">0.5</span>, <span class="fl">2.5</span>, <span class="fl">0.5</span>)), <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>)</code></pre></div>
<pre><code>##               setosa versicolor  virginica
## (0.0976,0.58]  1.000  0.0000000 0.00000000
## (0.58,1.06]    0.125  0.8750000 0.00000000
## (1.06,1.54]    0.000  0.9268293 0.07317073
## (1.54,2.02]    0.000  0.1724138 0.82758621
## (2.02,2.5]     0.000  0.0000000 1.00000000</code></pre>
</div>
<div id="eval_model" class="section level3">
<h3>eval_model</h3>
<p>eval_model is a simple function for evaluating a OneR classification model, which is included in the package for convenience reasons. It prints prediction vs. actual in absolute and relative numbers. Additionally, it gives the accuracy and error rate. The second argument “actual” is a dataframe which contains the actual data in the last column. A single vector is allowed too.</p>
<p>For the details please consult the available help entries.</p>
</div>
</div>
<div id="help-overview" class="section level2">
<h2>Help overview</h2>
<p>From within R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">help</span>(<span class="dt">package =</span> OneR)</code></pre></div>
<p>…or as a pdf here: <a href="https://cran.r-project.org/web/packages/OneR/OneR.pdf">OneR.pdf</a></p>
<p>Issues can be posted here: <a href="http://github.com/vonjd/OneR/issues" class="uri">http://github.com/vonjd/OneR/issues</a></p>
<p>The latest version of the package (and full sourcecode) can be found here: <a href="https://github.com/vonjd/OneR" class="uri">https://github.com/vonjd/OneR</a></p>
</div>
<div id="sources" class="section level2">
<h2>Sources</h2>
<p>[Holte93] R. Holte: Very Simple Classification Rules Perform Well on Most Commonly Used Datasets, 1993. Available online here: <a href="http://www.mlpack.org/papers/ds.pdf" class="uri">http://www.mlpack.org/papers/ds.pdf</a>.</p>
</div>
<div id="contact" class="section level2">
<h2>Contact</h2>
<p>I would love to hear about your experiences with the OneR package. Please drop me a note - you can reach me at my university account: <a href="https://www.h-ab.de/nc/eng/about-aschaffenburg-university-of-applied-sciences/organisation/personal/?tx_fhapersonal_pi1%5BshowUid%5D=jouanne-diedrich">Holger K. von Jouanne-Diedrich</a></p>
</div>
<div id="license" class="section level2">
<h2>License</h2>
<p>This package is under <a href="https://cran.r-project.org/web/packages/OneR/LICENSE">MIT License</a>.</p>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
